---
aliases: [scraping+texto+sentimiento]
title: 'Violencia hacia mujeres pol√≠ticas en X (ex-Twitter) en Uruguay (2024)'
thumbnail: ""
authors: [elina]
date: '2025-02-09'
tags: [Ciencias sociales computacionales]
codefolding_show: hide
codefolding_nobutton: true
categories:
  - R
  - Python
summary: 2025-02-09 / An√°lisis de la violencia y mensajes ofensivos hacia las mujeres pol√≠ticas en redes sociales, en particular en la red social X (ex-Twitter), en contexto de campa√±a electoral en Uruguay (2024). 
image:
  caption: ''
  focal_point: ''
  output:
  blogdown::html_page:
    toc: yes
    number_sections: true
    toc_depth: 4
featuredImage: ""
---




______________

El presente posteo presenta un procesamiento que realic√© en el marco de las columnas de an√°lisis de la [Usina de Percepci√≥n Ciudadana](https://usina.com.uy/) en el programa La Letra Chica de [TV Ciudad](https://usina.com.uy/tv-ciudad-2/) durante el a√±o 2024.

El objetivo era analizar la violencia y mensajes ofensivos hacia las mujeres pol√≠ticas en redes sociales, en particular en la red social X (ex-Twitter), en contexto de campa√±a electoral en Uruguay (2024). Existen antecedentes de estudios al respecto en Uruguay como es 
el trabajo de ONU MUjeres [Cuantificaci√≥n y an√°lisis de la violencia contra las mujeres pol√≠ticas en redes sociales - Uruguay](https://lac.unwomen.org/es/digital-library/publications/2022/03/cuantificacion-y-analisis-de-la-violencia-contra-las-mujeres-politicas-en-redes-sociales-uruguay) y en Argentina un art√≠culo reciente (2025) que analiza el discurso de odio hacia las mujeres pol√≠ticas en Twitter: [Promoters and targets in the Argentinean political context](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0317001).

En base a dichos antecedentes, se utilizan para este caso modelos de an√°lisis de sentimiento y detecci√≥n de mensajes de odio (hate speech) basados en aprendizaje autom√°tico, y se presentan algunas visualizaciones que tan cuenta tanto de la cantidad como del contenido de dichos mensajes. Se disponibilizan las [bases de datos](https://github.com/elinagomez/repo/tree/master/content/blog/2025-02-09-violencia-mujerespol/Datos) para replicar o ampliar procesamientos.

______________


**1. Conformaci√≥n de la muestra y scrapeo de datos**


A efectos de realizar un an√°lisis que pudiera ser comparable por g√©nero, necesitaba construir una muestra balanceada entre varones y mujeres pol√≠ticos/as que tuvieran una actividad importante en la red social analizada (X). Adem√°s, necesitaba considerar pol√≠ticos/as de los partidos con representaci√≥n parlamentaria, por lo que la muestra estuvo constituida por 6 legisladores y 6 legisladoras y, en cada caso, considerando un balance entre partidos seg√∫n peso parlamentario (2 FA, 2 PN 1 PC y 1 CA). Luego de esta definici√≥n, descargu√© v√≠a scraping (usando [Apify](https://apify.com/)) los √∫ltimos posteos organicos de cada figura pol√≠tica y los comentarios para cada una, conformando una muestra balanceada de comentarios entre g√©neros, 2468 comentarios a mujeres y 2140 para varones de 451 conversaciones (posteos). A continuaci√≥n la tabla resumen de la muestra seleccionada.

```{r echo=FALSE, message=FALSE, warning=FALSE}
load("C:/Users/elina/OneDrive/Documentos/repo/content/blog/2025-02-09-violencia-mujerespol/Datos/base_total.RData")

#librer√≠as

library(knitr)
library(kableExtra)
library(dplyr)
library(tidyr)
library(ggplot2)

base <- base %>%
  rename(
    Fecha = createdAt,
    Comentario = text,
    ID_Conversacion = conversationId,
    Vistas = viewCount,
    Nombre = nombre,
    Partido = partido,
    G√©nero = sexo
  )

# Generar tabla resumen con nombres personalizados
resumen <- base %>%
  group_by(Nombre, Partido, G√©nero) %>%
  summarize(
    `Comentarios` = n(),
    `Conversaciones` = n_distinct(ID_Conversacion)
  ) %>%
  arrange(G√©nero)

kable(resumen, format = "html", caption = "Tabla resumen muestra") %>%
  kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed", "responsive")) %>%
  row_spec(6, hline_after = TRUE) 

```


**2. An√°lisis de sentimiento con pysentimiento**


Luego de tener la base de datos consolidada, utilic√© la librer√≠a de Python [pysentimiento](https://github.com/pysentimiento/pysentimiento): _A Python toolkit for Sentiment Analysis and Social NLP tasks_. Tiene algunas funcionalidades de preprocesamiento y dos ventajas principales: fue entrenada con Tweets y tiene una implementaci√≥n del modelo para espa√±ol, por lo que su elecci√≥n se ajusta a los objetivos del trabajo. Adem√°s de el an√°lisis de sentimiento y detecci√≥n de mensajes de odio, que ser√°n las dos tareas ac√° utilizadas, tambi√©n reliza an√°lisis de emociones, reconocimiento de entidades, etiquetado de POS (Part of speech), entre otras. Este procedimiento lo hice con c√≥digo Python (no desde R) y el c√≥digo que utilic√© [est√° en este notebook de Google Colab](https://colab.research.google.com/drive/1ycr8032sUU13Ws1ceRjISkc0Ud2oIHK1?usp=sharing). Es muy sencillo!


**3. An√°lisis de resultados**


La librer√≠a _pysentimiento_ usa modelos basados en transformers en lugar de enfoques basados en diccionarios o reglas, lo que le permite captar matices y contexto en los textos. Clasifica los textos en sentimiento positivo, negativo y neutral. 

En primera instancia hice un an√°lisis de sentimiento de los comentarios a tweets y desagreg√© entre si fueron reacciones a legisladoras o a legisladores. Encontramos que hay un 5% de diferencia entre ambos en cuanto a comentarios negativos, siendo m√°s negativos aquellos que son dirigidos hacia mujeres, y 3% menos de comentarios positivos en el caso de las legisladoras.

```{r eval=FALSE, message=FALSE, warning=FALSE}
load("Datos/base_sent.RData")

base_sent <- base_sent %>%
  rename(
    Fecha = createdAt,
    Comentario = text,
    ID_Conversacion = conversationId,
    Vistas = viewCount,
    Nombre = nombre,
    Partido = partido,
    G√©nero = sexo
  )
##
sentgen = base_sent %>%
  group_by(G√©nero, sentimiento)%>%
  summarise(n = n()) %>%
  mutate(per = round((n / sum(n))*100 ,1) )

p1=sentgen %>%
  mutate(sexo = factor(G√©nero, levels = c("Mujer", "Varon"))) %>%
  ggplot(aes(x = G√©nero, y = per, fill = sentimiento)) +
  geom_col(width = 0.7) +
  geom_text(aes(label = paste0(per, "%")), 
            size = 5, colour = "black", fontface = "bold",
            position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("#ff9999", "#ffcc66", "#99cc99"), 
                    name = "Sentimiento", 
                    labels = c("Negativo", "Neutral", "Positivo")) +
  labs(title = "üìä Sentimiento en Comentarios de X (Twitter) a Pol√≠ticos/as Uruguayos/as",
       subtitle = "Distribuci√≥n del sentimiento por g√©nero en comentarios pol√≠ticos - 2024",
       x = NULL, y = "",
       fill = "Sentimiento") +
  theme_minimal(base_family = "Fira Sans Condensed", base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", colour = "black"),
    plot.subtitle = element_text(size = 12, colour = "grey40"),
    axis.text = element_text(size = 12, colour = "black"),
    legend.position = "top",
    panel.grid.major = element_line(color = "grey85"),
    panel.grid.minor = element_blank()
  ) +
  coord_flip()


```

<div class="responsive-iframe">
  <iframe src="Plots/p1.png" width="700" height="400"></iframe>
</div>

Luego, si vamos un poco y m√°s e identificamos la proporci√≥n de comentarios que incluyen mensajes ofensivos y de odio, tambi√©n vemos que es cercano al doble entre mujeres y varones.  


```{r eval=FALSE, message=FALSE, warning=FALSE}
load("Datos/base_hate.RData")

base_hate <- base_hate %>%
  rename(
    Fecha = createdAt,
    Comentario = text,
    ID_Conversacion = conversationId,
    Vistas = viewCount,
    Nombre = nombre,
    Partido = partido,
    G√©nero = sexo
  )
##
base_hate$hate_rec=ifelse(base_hate$hate=="[]","No","Si")

hatesex = base_hate %>%
  group_by(G√©nero, hate_rec)%>%
  summarise(n = n()) %>%
  mutate(per = round((n / sum(n))*100 ,1) )

p2 <- hatesex %>%
  filter(hate_rec == "Si") %>%
  mutate(G√©nero = factor(G√©nero, levels = c("Mujer", "Varon"))) %>%
  ggplot(aes(x = G√©nero, y = per, fill = hate_rec)) +
  geom_col(width = 0.6) +
  geom_text(aes(label = paste0(per, "%")), 
            size = 5, colour = "black", fontface = "bold",
            position = position_stack(vjust = 0.5)) +
  scale_fill_manual(values = c("#d73027"),  # Rojo fuerte para destacar
                    name = "Mensaje de odio",
                    labels = "S√≠") +
  ylim(0, 15) +
  labs(title = "üí¨ Mensajes de odio en Comentarios de X (Twitter) a Pol√≠ticos/as Uruguayos/as",
       subtitle = "Proporci√≥n de mensajes de odio seg√∫n el g√©nero del/la destinatario/a - 2024",
       x = NULL, y = "",
       fill = "Mensaje de odio",
       caption = "") +
  theme_minimal(base_family = "Fira Sans Condensed", base_size = 14) +
  theme(
    plot.title = element_text(size = 18, face = "bold", colour = "black"),
    plot.subtitle = element_text(size = 12, colour = "grey40"),
    plot.caption = element_text(size = 10, colour = "grey40"),
    axis.text = element_text(size = 12, colour = "black"),
    legend.position = "top",
    panel.grid.major = element_line(color = "grey85"),
    panel.grid.minor = element_blank()
  ) +
  coord_flip()

```


<div class="responsive-iframe">
  <iframe src="Plots/p2.png" width="700" height="400"></iframe>
</div>

Luego, interesaba indagar sobre el contenido de los comentarios a posteos que hab√≠an sido identificados como que inclu√≠an mensajes de odio e hice un an√°lisis de las palabras descalificativas u ofensivas que aparecen desagregadas por g√©nero de la figura pol√≠tica que hab√≠a realizado el posteo inicial. Se encuentran diferencias significativas, cuantitativas y cualitativas, ya que aparecen m√°s adjetivos y t√©rminos ofensivos en el caso de las mujeres pol√≠ticas. Sobre el contenido, en estas √∫ltimas se encuentra m√°s centrado en la persona (adjetivos como _rancia_, _boba_, _feminazi_, _borracha_, _est√∫pida_), al cuerpo ( _gorda_, _bagre_, _desprolija_) y apelaci√≥n al silencio ( _callate_, _calladita_ _shhhh_), mientras que en el caso de los varones se centra en mayor medida en lo ideol√≥gico ( _oligarca_, _anglosionista_, _traidor_, _delincuente_). El procesamiento fue hecho con la librer√≠a de R para an√°lisis de datos textuales [quanteda](https://quanteda.io/) y generaci√≥n de nubes de palabras con [wordcloud2](https://github.com/Lchiffon/wordcloud2).


```{r eval=FALSE, message=FALSE, warning=FALSE}

library(wordcloud2)

#mujer
hate_mujer_mas = subset(base_hate,base_hate$hate=="['hateful', 'targeted', 'aggressive']" & base_hate$sexo=="Mujer")
dfm =quanteda::dfm(quanteda::tokens(hate_mujer_mas$text_proc,remove_punct = TRUE,remove_numbers = TRUE),
tolower=TRUE,verbose = FALSE) %>%
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("spanish")),min_nchar=3)%>%
  quanteda::dfm_trim(min_termfreq = 1)

a=as.data.frame(topfeatures(dfm,423))
a$palabra=rownames(a)
dfm_select =quanteda::dfm(quanteda::tokens(hate_mujer_mas$text_proc,remove_punct = TRUE,remove_numbers = TRUE),tolower=TRUE,verbose = FALSE) %>%dfm_select(palabras$palabra)

f <- colSums(dfm)
a=wordcloud2(data.frame(names(f), f),size = 1, ellipticity = 1, shuffle = FALSE, shape = "circle",rotateRatio = 0) + WCtheme(1)

library(htmlwidgets)
saveWidget(a,"hate_mujer.html",selfcontained = F)


##varon

hate_varon_mas =subset(base_hate,(base_hate$hate=="['hateful', 'targeted', 'aggressive']" |
                         base_hate$hate=="['hateful', 'aggressive']" |
                         base_hate$hate=="['hateful', 'targeted']")
                         & base_hate$sexo=="Varon")

dfm_varon =quanteda::dfm(quanteda::tokens(hate_varon_mas$text_proc,remove_punct = TRUE,remove_numbers = TRUE),
tolower=TRUE,verbose = FALSE) %>%
  quanteda::dfm_remove(pattern = c(quanteda::stopwords("spanish"),stopES),min_nchar=3)%>%
  quanteda::dfm_trim(min_termfreq = 1)
f <- colSums(dfm_varon)
a=wordcloud2(data.frame(names(f), f),size = 1, ellipticity = 1, shuffle = FALSE, shape = "circle",rotateRatio = 0) + WCtheme(1)

saveWidget(a,"hate_varon.html",selfcontained = F)
```


<div class="responsive-iframe">
  <iframe src="Plots/wc1.png" width="700" height="400"></iframe>
</div>



Por √∫ltimo, centr√© el foco entre las mujeres pol√≠ticas seg√∫n partido, FA y Coalici√≥n, y se observa m√°s cantidad de t√©rminos ofensivos entre las primeras, incluso cuando en la muestra son minor√≠a, y diferencias en el tipo de palaras y adjetivos utilizados. Se presenta la visualizaci√≥n a continuaci√≥n. 



<div class="responsive-iframe">
  <iframe src="Plots/wc2.png" width="700" height="400"></iframe>
</div>

______________

FIN! Bases, c√≥digo y otros recursos disponibles para replicar o complementar el an√°lisis, como siempre, en mi [GitHub](https://github.com/elinagomez). 

<br>



