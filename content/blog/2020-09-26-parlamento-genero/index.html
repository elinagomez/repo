---
aliases: [G√©nero en el parlamento]
title: 'La tem√°tica de g√©nero en el Parlamento uruguayo'
thumbnail: ""
authors: [elina]
date: '2020-09-26'
tags: [G√©nero]
categories:
  - R
  - Miner√≠a de texto
  - G√©nero
  - An√°lisis cualitativo
  - Aprendizaje autom√°tico
summary: 2020-09-26 / Miner√≠a y clasificaci√≥n de texto con aprendizaje autom√°tico
image:
  caption: ''
  focal_point: ''
  output:
  blogdown::html_page:
    toc: false
    number_sections: true
    toc_depth: 1
featuredImage: ""
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>Este post surge a partir de la idea de aplicar algunas t√©cnicas de <em>miner√≠a de texto</em> y <em>clasificaci√≥n con aprendizaje autom√°tico</em> (o <em>machine learning</em>) para an√°lisis masivo de datos cualitativos usando R, de una tem√°tica que me interesaba particularmente como es el <strong>discurso pol√≠tico de g√©nero</strong>. Considero que la miner√≠a de texto es un √°rea que a√∫n no se encuentra tan difundida en Uruguay, que tiene mucho potencial y que puede ser aprovechada desde las ciencias sociales como aporte para sumar o complementar las herramientas metodol√≥gicas m√°s tradicionales.</p>
<p>El <strong>objetivo general</strong> del trabajo es lograr un buen m√©todo de clasificaci√≥n de texto que me permita distinguir entre las intervenciones parlamentarias en la C√°mara de representantes (unidad m√≠nima de an√°lisis) que planteen y discutan la tem√°tica de g√©nero para luego analizar mediante variables anexas, qu√© representantes, partidos, sectores son los que instalan la discusi√≥n en dicha materia <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<p>El post se va a estructurar en cuatro partes:</p>
<ol style="list-style-type: decimal">
<li><strong>Obtenci√≥n de la informaci√≥n (web scraping)</strong></li>
<li><strong>Limpieza del texto y matriz de t√©rminos</strong></li>
<li><strong>Clasificaci√≥n: machine lerning y diccionario</strong></li>
<li><strong>An√°lisis de los datos</strong></li>
</ol>
<hr />
<div id="obtenci√≥n-de-la-informaci√≥n-web-scraping" class="section level2">
<h2>1. Obtenci√≥n de la informaci√≥n (web scraping)</h2>
<p>En lo que respecta a la fuente de datos, mi primera inspiraci√≥n estuvo en <a href="https://d4tagirl.com/2018/04/de-qu%C3%A9-se-habl%C3%B3-en-el-parlamento-uruguayo-desde-2017">este post</a> de 2018 de <a href="https://d4tagirl.com/"><em>d4tagirl</em></a> que trataba sobre la obtenci√≥n de datos directamente desde internet (<em>web scraping</em>), de las sesiones parlamentarias (cuyas transcripcioes son de libre acceso) y an√°lisis de las frecuencias de las sesiones, visualizaci√≥n de las palabras m√°s relevantes, an√°lisis de sentimiento, etc.</p>
<p>Luego de esto, en 2019 se desarrolla por parte de un equipo<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> de la <em>Facultad de Ciencias Sociales</em> (UdelaR), el paquete <a href="https://cran.r-project.org/web/packages/speech/index.html">speech</a>, el cual permite descargar las sesiones parlamentarias de forma f√°cil y ordenada, agregando a los discursos algunas variables anexas como la legislatura, el nombre (lo cual me permite rastrear algunas caracter√≠sticas), la fecha de la sesi√≥n, entre otras. Esto me facilit√≥ mucho el trabajo de recolecci√≥n de informaci√≥n inicial üôá‚Äç‚ôÄ !.</p>
<p>Para el an√°lisis, decid√≠ acotar el universo a los discursos e intervenciones de lxs diputadxs (ya que incluir ambas c√°maras era un vol√∫men demasiado grande de informaci√≥n!), correspondientes a la legislatura pasada: <strong>XLVIII (2015-2020)</strong>. La transcripciones taquigr√°ficas de las sesiones parlamentarias se encuentran en archivos formato <em>pdf</em> en la <a href="https://parlamento.gub.uy/">p√°gina del parlamento</a>, en la cual se pueden hacer b√∫squedas manuales seg√∫n legislatura, fechas, identificadores de sesi√≥n y Diario, etc. Lo que yo necesitaba entonces era obtener todas las transcripciones del per√≠odo, las cuales metiante una b√∫suqueda simple filtrando la legislatura, s√≥lo para la C√°mara de representantes asciend√≠an a <strong>308</strong> Diarios de sesiones.</p>
<p>Como primer paso para la obtenci√≥n de la informaci√≥n deb√≠a recolectar todas las rutas a los archivos <em>pdf</em> lo cual me permitir√≠a aplicar la funci√≥n <strong>speech_build()</strong> del paquete <a href="https://cran.r-project.org/web/packages/speech/index.html">speech</a> y transformar la informaci√≥n que se encuentra en <em>pdf</em> en un <em>data frame</em> ordenado.</p>
<p>Una opci√≥n v√°lida, pero ineficiente, hubiera sido copiar <em>‚Äúa mano‚Äù</em> las 308 rutas a cada uno de los <em>pdf</em>, sin embargo indagando un poco en el post de <em>d4tagirl</em> sobre <a href="https://d4tagirl.com/2018/04/scrapeando-las-sesiones-parlamentarias-de-uruguay">web scraping</a> (recomiendo!) y en foros, agregu√© alguna cosa y llegu√© a una soluci√≥n para automatizar la recolecci√≥n considerando incluso que, dada la cantidad, los mismos se encuentran desplegados en diferentes p√°ginas.</p>
<pre class="r"><code>#Cargo paquetes:
library(dplyr) #manipulaci√≥n
library(rvest) #web scraping  
library(purrr) #iteraci√≥n 

##creo un objeto &quot;ruta&quot; que es el url ra√≠z para luego pegarle la terminaci√≥n seg√∫n el n√∫mero de p√°gina del cual me interesa objeter las url a los pdf. 
ruta= &quot;https://parlamento.gub.uy/documentosyleyes/documentos/diarios-de-sesion?Cpo_Codigo_2=D&amp;Lgl_Nro=48&amp;DS_Fecha%5Bmin%5D%5Bdate%5D=15-02-2015&amp;DS_Fecha%5Bmax%5D%5Bdate%5D=14-02-2020&amp;Ssn_Nro=&amp;TS_Diario=&amp;tipoBusqueda=T&amp;Texto=&quot;
paginas=as.character(c(0:7)) ##defino la cantidad de paginas, en este caso 8 (del 0 al 7)

##creo un objeto &quot;url&quot; d√≥nde me va a guardar el vector de las 308 rutas que necesito!

url &lt;- map(paginas,~ paste0(ruta, &quot;&amp;page=&quot;, .))%&gt;% #pego el pedazo de ruta para hacer referencia al n√∫mero de p√°gina
       unlist() %&gt;% 
       map(~ .x  %&gt;% ## con la funci√≥n map() de purr, √≠tero a lo largo del vector &quot;paginas&quot;
       read_html() %&gt;%  ##funci√≥n de rvest para obtener contenido en formato html 
       html_nodes(&quot;.views-field-DS-File-IMG a&quot;) %&gt;% #identifica qu√© parte o nodo espec√≠fico me interesa   
       html_attr(&quot;href&quot;) %&gt;%
       map(~ paste0(&quot;https://parlamento.gub.uy&quot;, .)))%&gt;%
       unlist()</code></pre>
<p>En este punto lo que tengo es un vector con 308 elementos, en el cual cada uno es una ruta a un Diario de sesi√≥n en formato pdf. Luego, aplico la funci√≥n <strong>speech_build()</strong> para que ordene en un data frame todas las intervenciones contenidas en cada uno de los Diarios, con informaci√≥n anexa como ya lo mencion√©.</p>
<pre class="r"><code>#Cargo paquetes:
library(speech) #scraping parlamentario

#aplico la funci√≥n speech_build() iterando sobre cada una de las rutas y alojandolo en un objeto &quot;discursos_diputadxs&quot;

discursos_diputadxs &lt;- map(url,possibly(speech_build,otherwise = NULL))

#Importante: ac√° tuve alg√∫n problema grande con pdf en los cuales no se pod√≠an identificar intervenciones y me cortaban el proceso, lo cual solucion√© con la funci√≥n possibly() de purr, la cual omite el error y contin√∫a aplicando la funci√≥n.   </code></pre>
<p>Al final de este proceso (que demora bastante!), obtuve una base con <strong>23990</strong> intervenciones para todo el per√≠odo. Cabe aclarar que la funci√≥n <strong>speech_build()</strong> tiene un argumento <em>quality</em> que te permite, mediante un par de indicadores, dar cuenta de la calidad de la conversi√≥n a partir de la proporci√≥n del documento que pudo ser recuperado. Tambi√©n otro argumento que permite agregar o compilar la informaci√≥n por legislador, en este caso obtuve cada menci√≥n por separado.</p>
<p>Hasta este momento ten√≠a una gran base de todas las intervenciones de la legislatura pasada en bruto y que necesitaba clasificar en aquellas que trataban la tem√°tica de g√©nero y aquellas que no. Deb√≠a conseguir entonces documentos que hablaran de g√©nero y otros que no, as√≠ pod√≠a aplicar un modelo que <em>aprendiera</em> a distinguir entre estos dos discursos y me permitiera clasificar las intervenciones (machine lerning o aprendizaje autom√°tico).Para esto podr√≠a haber etiquetado de forma <em>artesanal</em> las intervenciones que trataran la tem√°tica de g√©nero y aquellas que no, pero me implicaba mucho tiempo (que no tengo!) y entonces se me ocurri√≥ una ideaüí°: en la pagina del parlamento hay unos documentos de las transcripciones de las diferentes comisiones tem√°ticas que integran lxs propixs parlamentarixs y existe una espec√≠fica de <a href="https://parlamento.gub.uy/documentosyleyes/documentos/versiones-taquigraficas?Cpo_Codigo=D&amp;Lgl_Nro=48&amp;Fecha%5Bmin%5D%5Bdate%5D=15-02-2015&amp;Fecha%5Bmax%5D%5Bdate%5D=14-02-2020&amp;Cms_Codigo=1090&amp;Dtb_Nro=&amp;tipoBusqueda=T&amp;Texto=&amp;Cuerpo=">Equidad y g√©nero</a> con <strong>28</strong> documentos disponibles, por lo que con la misma t√©cnica anterior, elabor√© una base de datos con todas las intervenciones de dicha comisi√≥n y otra base con intervenciones de diferentes comisiones parlamentarias con temas variados: presupuesto, hacienda, asuntos internacionales, salud, turismo, ambiente, etc.</p>
<p>Finalmente, constru√≠ una base que servir√° de <em>entrenamiento</em> con ambos tipos de intervenciones y una variabla de agregaci√≥n llamada <em>genero</em> con dos valores: <em>Si genero</em> / <em>No genero</em>.</p>
</div>
<div id="limpieza-del-texto-y-matriz-de-t√©rminos" class="section level2">
<h2>2. Limpieza del texto y matriz de t√©rminos</h2>
<p>En este momento necesitaba aplicar algunas funciones que me permitieran <em>limpiar</em> el texto y quedarme con lo que realmente me interesa y que me permite distinguir entre palabras que dan cuenta de un discurso que hace referencia a la tem√°tica de g√©nero y aquellos que no. Este es un trabajo que lleva mucho tiempo (tal vez el que m√°s!), mucho ensayo y error, y a veces resulta tedioso, pero es el m√°s importante para que los resultados tengan sentido y lograr hacer una buena clasificaci√≥n y an√°lisis posterior.</p>
<p>En un primer momento esto lo hice para la base de <em>entrenamiento</em> que inclu√≠a intervenciones de las comisiones, las cuales aloj√© en un <em>corpus</em> d√≥nde cada una es un elemento del mismo. El resultado de este paso ser√° una una matriz de t√©rminos (en este caso palabras, pero podr√≠an ser expresiones tambi√©n!) que se denomina <em>document-feature matrix</em> (dfm) en el paquete <strong>quanteda</strong> que es el que voy a utilizar. Esta matriz contiene tantas filas como elementos del corpus haya (en este caso intervenciones) y tantas columnas como t√©rminos, en las celdas se encuentra la frecuencia de aparici√≥n de cada t√©rmino en cada intervenci√≥n.</p>
<p>Como primer paso para llevar a cabo la limpieza, me interesa eliminar todas las intervenciones que cuenten con menos de 13 palabras ya que, seg√∫n he le√≠do, corresponden con expresiones o asuntos de √≥rden ( <em>‚ÄúPido la palabra‚Äù</em>, <em>‚ÄúVoto la moci√≥n de‚Ä¶‚Äù</em>, etc.) que no me dicen nada para mi an√°lisis. Esto lo hago en un primer momento con la funci√≥n <em>corpus trimsentences()</em> al momento de crear el corpus y decirle la variable en d√≥nde se encuentra el discurso ( <em>speech</em> en este caso).</p>
<p>En un segundo momento, aplico la funci√≥n <em>dfm()</em> al corpus previamente creado para limpiar y construir la matriz. Para esto, uso un vector que tengo pre-cargado y que llamo <strong>palabras_drop</strong> y que me ayudan a eliminar t√©rminos que no me interesan, el cual contiene:</p>
<ul>
<li><strong>nombres</strong> y <strong>apellidos</strong> de lxs diputadxs</li>
<li><strong>stopwords</strong> y modismos uruguayos</li>
<li><strong>palabras espec√≠ficas</strong> que se reiteran en las trascripciones (se√±or, se√±ora, dipudato, diputada, taquigr√°fico y varias m√°s)</li>
</ul>
<p>En el c√≥digo explico cada paso:</p>
<pre class="r"><code>#Cargo paquetes:
library(quanteda) #miner√≠a de texto

entrenamiento &lt;- quanteda::corpus(train,text_field = &quot;speech&quot;)%&gt;%
  quanteda::corpus_trimsentences(min_length = 13) # quito las intervenciones que tienen menos de 13 palabras 

entrenamiento_dfm &lt;- quanteda::dfm(entrenamiento,
                         tolower = TRUE, #transforma todo a min√∫scula
                         remove_punct = TRUE, #elimina puntuaci√≥n  
                         remove_numbers = TRUE,  #elimina n√∫meros 
                         remove = c(stopwords::stopwords(&quot;spanish&quot;),palabras_drop), #elimina stopwords pre-cargadas en quanteda y palabras espec√≠ficas de inter√©s
                         verbose = TRUE) %&gt;% #imprime un resumen del proceso
  quanteda::dfm_remove(min_nchar=3)%&gt;% # elimino las palabras que tienen 1 y 2 caracteres
  quanteda::dfm_trim(min_termfreq = 90) #le indico que se quede con t√©minos que aparezcan al menos 90 veces (Esto se va calibrando en la marcha!). Me permite sacar los t√©rminos que se usan muy poco. </code></pre>
<p>Ac√° me interesa ver si me est√° agregando bien las palabras y hago una nube de palabras con la funci√≥n <strong>textplot_wordcloud()</strong>, para ello le defino la variable <em>genero</em> como de agrupaci√≥n y el argumento <em>comparison=T</em> para mostrar la segmentaci√≥n.</p>
<pre class="r"><code>quanteda.textplots::textplot_wordcloud(quanteda::dfm(entrenamiento_dfm, groups = &quot;genero&quot;), min.count = 10,max_words = 300,random.order = TRUE,rot.per = .25, colors = c(&quot;#954342&quot;,&quot;#e76363&quot;),comparison = T)</code></pre>
<p><img src="imagenes/nube.png" /></p>
<p>Me quedo conform√© con las palabras que me muestra!</p>
</div>
<div id="clasificaci√≥n-aprendizaje-autom√°tico-y-diccionario" class="section level2">
<h2>3. Clasificaci√≥n: aprendizaje autom√°tico y diccionario</h2>
<p>El <a href="https://es.wikipedia.org/wiki/Aprendizaje_autom%C3%A1tico"><em>aprendizaje autom√°tico</em></a> (o machine learning) es un procedimiento que permite automatizar algunas operaciones reduciendo la necesidad de intervenci√≥n de un ser humano, a partir de la identificaci√≥n o <em>aprendizaje</em> de ciertos patrones seg√∫n par√°metros determinados y posterior predicci√≥n en otro conjunto de datos.</p>
<p>En este caso, tengo la matriz de t√©minos creada a partir de mi base de entrenamiento (creada en el punto 1) y categorizada con la variable <em>‚Äúgenero‚Äù</em> de forma equilibrada seg√∫n si las mismas fueron realizadas en la <em>Comisi√≥n de Equidad y g√©nero</em> o en otras comisiones tem√°ticas. Ahora tengo que aplicar un modelo que permita <em>aprender</em> qu√© t√©rminos distinguen entre un discurso que trata g√©nero y uno que no. Para ello existen diferentes tipos de t√©cnicas y modelos, m√°s sencillos y m√°s complejos, en este caso usar√© el modelo predictivo de clasificaci√≥n llamado <a href="https://es.wikipedia.org/wiki/Random_forest"><em>Random forest</em></a> (o bosques aleatorios en espa√±ol), con el paquete <a href="https://cran.r-project.org/web/packages/randomForest/index.html"><em>random Forest</em></a>. Para ello, creo dos grupos aleatorios para entrenar y testear el modelo, todo dentro de la matriz de t√©rminos ya creada. Para definir con qu√© modelo me quedo, pruebo diferentes opciones de par√°metros y eval√∫o seg√∫n la precisi√≥n en la predicci√≥n.</p>
<pre class="r"><code>#Cargo paquetes:
library(randomForest) #correr modelo
library(tidymodels) #lo uso s√≥lo para crear grupos para entrenamiento y prueba

##primero convierto la matriz en un data frame
entrenamiento_dfm &lt;- entrenamiento_dfm %&gt;%
  convert(to = &quot;data.frame&quot;)%&gt;%
  mutate(genero=docvars(entrenamiento_dfm, &quot;genero&quot;))

set.seed(23) #hago reproducible la selecci√≥n aleatoria

genero_split &lt;- initial_split(entrenamiento_dfm, strata = genero) ##divide aleatoriamente seg√∫n un estrato, ac√° es genero y genera dos sub grupos: entreno y testeo
entreno &lt;- training(genero_split) 
testeo &lt;- testing(genero_split)

##Con la variable randomForest se aplica el algoritmo y guardo el modelo
modelo &lt;- randomForest(genero ~ ., data=entreno)
##OOB 
#0.1582538 

##lo uso para predecir en los grupos: entreno y testeo 
prediccion_entreno &lt;- predict(modelo, newdata=entreno)
prediccion_testeo &lt;- predict(modelo, newdata=testeo)

##Eval√∫o el modelo

##veo la matriz de confusi√≥n y veo en cuantos predijo bien y en cuantos no

# table(entreno$genero, prediccion_entreno)
#  prediccion_entreno
#               No genero Si genero
#   No genero       372         1
#   Si genero        23       337
#accuracy 96.7%

# table(testeo$genero, prediccion_testeo)
#  prediccion_testeo
#              No genero Si genero
#  No genero       111        13
#  Si genero        31        88
#accuracy 81.9%</code></pre>
<p>Luego de tener este modelo y ver que funciona bastante bien, lo que hago es cargar mi base de las intervenciones de todxs lxs diputadxs, aplico una limpieza similar al punto 2 y me quedo con las sentencias y palabras que me sirven en una matriz de t√©rminos. En esta limpieza, de <strong>23990</strong> intervenciones paso a <strong>13437</strong>, poco m√°s de la mitad.</p>
<p>Luego me quedo con los t√©rminos coincidentes en ambos casos y predigo en mi base sin clasificaci√≥n alguna.</p>
<pre class="r"><code>##me quedo con los t√©rminos coincidentes entre la base que us√© para predicir y la que quiero predecir

entrenamiento_dfm_final &lt;-data.frame(entreno[,colnames(entreno)%in%colnames(diputados_dfm)])
diputados_dfm_final &lt;- data.frame(diputados_dfm[,colnames(diputados_dfm)%in%colnames(entreno)])

##hago la predicci√≥n
prediccion_todo &lt;- predict(modelo, newdata=diputados_dfm_final)

#lo convierto en data frame y filtro los que fueron predecido como &quot;Si genero&quot;
sigenero &lt;- diputados%&gt;%
  convert(to = &quot;data.frame&quot;)%&gt;%
  mutate(genero=prediccion_todo) %&gt;%
  filter(genero=&quot;Si genero&quot;) </code></pre>
<p>En este momento tengo una base con una clasificaci√≥n entre: <em>Si genero</em> / <em>No genero</em> generada a partir de la aplicaci√≥n del algoritmo random forest con intervenciones que tocan la tem√°tica de g√©nero. En este punto, podr√≠amos comenzar el an√°lisis viendo como se sub divide entre partidos, legisladorxs, etc, pero tomo algunas intervenciones y, m√°s all√° de que muchas est√°n bien clasificadas, veo que algunas tocan el tema pero muy tangencialmente o se entran en la proporci√≥n de error del modelo y directamente no hablan del tema, por lo que se me ocurre la idea de afinar un poco m√°s la clasificaci√≥n y combinar con la t√©cnica de diccionario de <strong>quanteda</strong>, considerando los 50 t√©minos m√°s usados en mi base de entrenamiento (limpia) para el grupo <em>Si g√©nero</em> como un diccionario a aplicar a mis intervenciones pre-clasificadas.</p>
<pre class="r"><code> ##top t√©rminos por grupo
 dicgenero &lt;- entrenamiento_dfm %&gt;%
   quanteda::topfeatures(50,groups = &quot;genero&quot;)
dicgenero &lt;- rownames(as.data.frame(dicgenero[[2]]))
##lo convierto en diccionario (formato lista) con la funci√≥n dictionary()  
idc_dicgenero &lt;-dictionary(list(genero=dicgenero))
##aplico la funci√≥n dfm_lookup() para evaluarlo en un dfm nuevo s√≥lo de la base pre-clasificada
midic_result_dicgen &lt;- data.frame(dfm_lookup(sigenero_dfm,dictionary=idc_dicgenero))

base_final &lt;-  sigenero %&gt;%
              left_join(y=midic_result_dicgen,by=&quot;doc_id&quot;)%&gt;%
              filter(diccionario&gt;=30)</code></pre>
<p>Luego de aplicar el diccionario, opto por quedarme con aquellas intervenciones que tienen &gt;=30 palabras del mismo y as√≠ asegurarme que est√°n bien clasificadas. Luego de esto al fin llego a una base final con <strong>745</strong> intervenciones que tratan g√©nero üòÑ!</p>
<p>Para mi an√°lisis necesito dar cuenta del g√©nero de lxs diputadxs, el partido, sector, etc, por lo que la variable que lxs identifica, toma unicamente el primer apellido que se encuentra en la trascripci√≥n, por lo que tuve que hacer un trabajo artesanal de identificar a qu√© legisladorxs se refer√≠a y pegar ese dato con la informaci√≥n anexa que me interesa (me complicaron mucho los apellidos repetidos: Rodriguez, Cardoso, Umpi√©rrez, Viera y algunos m√°s)</p>
</div>
<div id="an√°lisis-de-los-datos" class="section level2">
<h2>4. An√°lisis de los datos</h2>
<p>En este apartado presento algunos datos generales que se desprenden de mi base de menciones sobre g√©nero.</p>
<p>En primer lugar, observando la evoluci√≥n de menciones sobre el tema se registra un aumento de las mismas hacia el final de la legislatura, con diferencias entre partidos.</p>
<p><strong>Evoluci√≥n de las menciones en el tiempo por partido pol√≠tico</strong></p>
<p><strong>Menciones por partido pol√≠tico</strong></p>
<p>Si vemos la distribuci√≥n de las menciones relativas al g√©nero por partido pol√≠tico en t√©rminos absolutos, vemos que el <strong>Frente Amplio</strong> es el que cuenta con m√°s menciones ( <strong>364</strong>), seguidas por el <strong>Partido Nacional</strong> ( <strong>230</strong>).</p>
<p><strong>Menciones por g√©nero</strong></p>
<p>Si nos centramos en el g√©nero de lxs legisladorxs, el <strong>56.5%</strong> de las intervenciones son de varones y el <strong>43.5%</strong> por mujeres. Sin embargo, si relativizamos por la cantidad de mujeres y varones diputadxs vemos que la cantidad de menciones por legisladorx es mayor en el caso de las mujeres con respecto a los varones, de hecho podemos decir que las diputadas mujeres hablan <strong>1.3</strong> m√°s que los varones.</p>
<p><strong>Legisladorxs</strong></p>
<p>Por √∫ltimo, queremos ver qu√© legisladorxs son lxs que tienen m√°s intervenciones referidas al g√©nero y observamos que, a pesar de que el Frente Amplio era el partido que registraba m√°s menciones absolutas, quienes acumulan m√°s intervanciones referidas al tema son diputadas del Partido Nacional y Partido Colorado. Tambi√©n vemos que, entre lxs 10 principales, la gran mayor√≠a son mujeres, esto ratifica la idea de que las mujeres son las que m√°s instalan la tem√°tica de g√©nero, reafirmando la necesidad de paridad y participaci√≥n equilibrada en la representaci√≥n parlamentaria.</p>
<hr />
<p>Espero que les haya gustado y servido, seguro que existen muchas cosas por mejorar y mucho potencial a√∫n para ahondar y enriquecer la investigaci√≥n social a partir del an√°lisis del texto y de la palabra.</p>
<hr />
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>En este punto cabe aclarar que se hace un an√°lisis del tratamiento de la tem√°tica sin valoraciones positivas o negativas en los discursos, lo cual podr√≠a eventualmente analizarse mediante la t√©cnica de an√°lisis de sentimento.<a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p><a href="https://github.com/Nicolas-Schmidt">Nicolas Schmidt</a> [aut, cre], Diego Lujan [aut], Juan Andres Moraes [aut]<a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>
