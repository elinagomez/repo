---
aliases: [GPT-3 ciencias sociales]
title: 'Uso de GPT-3 en las ciencias sociales: algunas ideas'
thumbnail: ""
authors: [elina]
date: '2023-02-21'
tags: [Ciencias sociales computacionales]
categories:
  - R
  - Miner√≠a de texto
  - GPT-3
summary: 2023-02-21 / Uso de GPT-3 para reducci√≥n de texto
image:
  caption: ''
  focal_point: ''
  output:
  blogdown::html_page:
    toc: false
    number_sections: true
    toc_depth: 1
featuredImage: ""
---

<script src="{{< blogdown/postref >}}index_files/header-attrs/header-attrs.js"></script>


<p>En esta entrada me interesaba indagar acerca de las potencialidades que podr√≠a tener GPT-3, desde el punto de vista metodol√≥gico, para las investigaciones que hacemos en ciencias sociales, pero‚Ä¶empezando por el principio <strong>¬øqu√© es GPT-3?</strong></p>
<p>Bueno, <strong>GPT-3</strong> es un modelo de lenguaje basado en Inteligencia Artificial (IA), desarrollado por la empresa <a href="https://openai.com/">OpenAI</a>, que ha tenido gran repercusi√≥n en los √∫ltimos meses y que tiene capacidad de predecir palabras o frases dado un contexto determinado. El texto que genera es posible a trav√©s de un pre-entrenamiento de modelo con un gran volumen de datos textuales de lenguaje natural. El acceso gratuito tiene un tope (U$S 18 para usar en 3 meses) y podemos conectarlo con RStudio.</p>
<hr />
<p>Presento dos posibles aplicaciones para optimizar nuestros procesos:</p>
<ol style="list-style-type: decimal">
<li><p>Identificaci√≥n de t√≥picos o temas (binarios) en textos medianos o largos.</p></li>
<li><p>Codificaci√≥n de preguntas abiertas a partir de <em>codigueras pre-definidas</em> o <em>emergentes</em></p></li>
</ol>
<hr />
<p>La librer√≠a que us√© para el procesamiento es <a href="https://github.com/ben-aaron188/rgpt3">rgpt3</a> de Bennett Kleinberg (2022)<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>.</p>
<p>El paquete tiene una funci√≥n que se llama <strong>gpt3_authenticate()</strong> y que te permite, luego de crear un usuario <a href="https://openai.com/api/">ac√°</a>, acceder a una <a href="https://platform.openai.com/account/api-keys">clave</a> que va a permitirte conectar con la API de GPT-3. La clave debe ser guardada en un archivo de notas (.txt) y va a ser el primer argumento de la funci√≥n para conectar. Luego, chequeo que la conexi√≥n se estableci√≥ con √©xito con la funci√≥n <strong>gpt3_test_completion()</strong></p>
<pre class="r"><code>#Cargo paquete ya instalado:
library(rgpt3)

gpt3_authenticate(&quot;ruta/access_key.txt&quot;) ##le indico d√≥nde tengo guardado el archivo con la clave
gpt3_test_completion() ##testeo la conexi√≥n</code></pre>
<hr />
<p>Luego de estos pasos previos, <strong>ya tengo conectada</strong> mi consola R + RStudio con la API de GPT-3 !</p>
<p>Empecemos‚Ä¶üí™</p>
<hr />
<p><strong>1.</strong> Identificaci√≥n de t√≥picos o temas (binarios) en textos medianos o largos.</p>
<p>Me interesa saber, m√°s all√° de una clasificaci√≥n gen√©rica de menciones parlamentarias que tocan la tem√°tica de g√©nero(como lo hice en una entrada anterior), saber cuales de ellas hablan espec√≠ficamente del tema <em>violencia de g√©nero</em>, y para eso uso la asistencia del modelo GPT-3 para que me ayude a identificarlas. Seg√∫n algunos ensayos previos, veo que lo m√°s optimo es hacerlo en dos pasos: en primer lugar le pido que identifique un <em>Tema principal</em> en cada menci√≥n (lo cual ya me podr√≠a ser √∫til y analizable en s√≠ mismo), ya que la intervenci√≥n podr√≠a tratar varios temas y, en segundo lugar, le doy una orden concreta para que identifique si ese tema se vincula con mi t√≥pico de inter√©s y le sugiero devolverme un <strong>Si</strong> si le parece que lo trata y un <strong>No</strong>, en el caso contrario.</p>
<p><em>Nota:</em> Esto tambi√©n podr√≠a servir para un an√°lisis r√°pido de corpus de noticias o post de redes sociales. M√°s adelante vamos a ver que para textos cortos utilizo otra estrategia de clasificaci√≥n/extracci√≥n de t√≥picos.</p>
<p>Las ordenes que le voy a dar son: <em>‚ÄòIdentifique un tema principal en el siguiente texto:‚Äô</em> y <em>‚ÄòEste texto habla sobre violencia de g√©nero? Responda √∫nicamente Si o No‚Äô</em> y luego, le pego cada una de las menciones y variables de origen de cada parlamentario/a, de este modo para el segundo caso:</p>
<pre class="r"><code>prompt = data.frame(&#39;prompts&#39; = c(paste(&#39;La siguiente frase menciona la violencia de g√©nero? Responda √∫nicamente Si o No&#39;,base$speech)),&#39;prompt_id&#39; = c(1:nrow(base)))



consulta = gpt3_completions(prompt_var = prompt$prompts # defino las √≥rdenes, una por cada menci√≥n
                             , id_var = prompt$prompt_id # el identificador
                             , param_model = &#39;text-davinci-003&#39;, ##defino el modelo
                            param_max_tokens = 2000,param_output_type = &quot;complete&quot;,
                            param_temperature = 0) ##defino algunos par√°metros: max_tokens (cuanto me va a traer como m√°ximo, debe ser mayor que mi N y temperature que est√° entre 0 y 1, siendo las respuestas que se acercan a 1 m√°s aleatorias) 

respuestas=consulta[[1]] ##veo el primer elemento en mi lista que es mi data frame de respuestas
base=cbind(base,respuestas) ##le pego las respuestas a la base original</code></pre>
<p>Los resultados de la reducci√≥n del texto en dos pasos son lo que se muestran en la siguiente tabla, la variable <strong>gpt3_1</strong> nos da una idea del tema principal del texto largo, y luego utilizo esa variable para identificar un tema espec√≠fico:</p>
<iframe src="t1.html" width="700" height="500">
</iframe>
<hr />
<p><br /></p>
<p><strong>2.</strong> Codificaci√≥n de preguntas abiertas a partir de <em>codigueras pre-definidas</em> o <em>emergentes</em></p>
<p>Otra aplicaci√≥n posible ser√≠a el tratamiento de preguntas abiertas usando el GTP-3 como un asistente para la codificaci√≥n (lo cual nos podr√≠a ahorrar mucho tiempo!), al menos para una clasificaci√≥n inicial cuando tenemos muchos casos.</p>
<p>Identifico dos formas: (a) <em>Codigueras pre-definidas</em> o (b) <em>Emergentes</em></p>
<hr />
<p><br /></p>
<p>En el primer caso, dentro de la orden que le damos y que vimos anteriormente, le defino las categor√≠as que deseo que identifique. Hay una publicaci√≥n reciente (Bailey et al, 2022)<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> que compara para un dataset de preguntas abiertas, un codificador humano, un modelo de aprendizaje autom√°tico (SVM) y el modelo GPT-3, y encuentra niveles de acierto altos(recomiendo la lectura! aunque sin dudas deben existir ventajas en el ingl√©s).</p>
<p>El ensayo que hice fue de una encuesta de opini√≥n p√∫blica, sobre la t√≠pica pregunta sobre los principales problemas del pa√≠s, en este caso lo ideal es tener una respuesta √∫nica pero sin embargo, se puede definir en la orden (prompt) un criterio de priorizaci√≥n de alg√∫n tipo (ej. primera menci√≥n).</p>
<p><br /></p>
<pre class="r"><code>prompt = data.frame(&#39;prompts&#39; = c(paste(&quot;Tengo algunas respuestas abiertas de una encuesta que pregunta lo siguiente: ¬øqu√© cosas le preocupan en su vida?. 
Por favor, asigne una de las siguientes categor√≠as a cada respuesta de texto abierto.
La categor√≠a son: 

salud
econom√≠a
educaci√≥n 
seguridad
pol√≠tica
pobreza
sueldos
desempleo
corrupci√≥n
suba de precios
espacios
transporte p√∫blico
migraci√≥n
vivienda
costo del estado

Si no es ninguna de las anteriores por favor asigne la categor√≠a Otros&quot;,
base_op$R1)),&#39;prompt_id&#39; = c(1:nrow(base_op)))

consulta = gpt3_completions(prompt_var = my_prompts$prompts
                            , id_var = my_prompts$prompt_id
                            , param_model = &#39;text-davinci-003&#39;,
                            param_max_tokens = 500,param_temperature = 0,
                            param_output_type = &quot;complete&quot;)


respuestas=consulta[[1]]
base_op=cbind(base_op,respuestas)</code></pre>
<p><br /></p>
<p>Los resultados que obtengo son los que se encuentran en la sigiente tabla, seg√∫n los c√≥digos sugeridos en mi orden. Esta categorizaci√≥n es m√°s f√°cil de procesar, por ejemplo separando en diferentes columnas considerando la coma como separador y luego contabilizando menciones para cada c√≥digo:</p>
<p><br /></p>
<iframe src="t2.html" width="700" height="500">
</iframe>
<p><br />
<br /></p>
<hr />
<p>Por √∫ltimo, en el caso de preguntas que no tengan, o sea dif√≠cil, una codificaci√≥n previa, voy a optar por una orden m√°s concreta que me permita identificar c√≥digos <em>emergentes</em>. En el ejemplo que utilic√©, era una pregunta tambi√©n de opini√≥n p√∫blica orientada en conocer sobre qu√© genera bienestar de las personas consultadas. La orden dise√±ada fue:</p>
<p><br /></p>
<pre class="r"><code>prompt = data.frame(&#39;prompts&#39; = c(paste(&quot;Tengo algunas respuestas abiertas de una encuesta que pregunta: ¬øQu√© cosas le causan bienestar, qu√© le hace feliz o le pone contento?. 
Por favor identifique en pocas palabras las principales respuestas&quot;,base_op$R2)),
&#39;prompt_id&#39; = c(1:nrow(base_op)))

consulta = gpt3_completions(prompt_var = prompt$prompts
                            , id_var = prompt$prompt_id
                            , param_model = &#39;text-davinci-003&#39;,param_max_tokens = 2000,
                            param_temperature = 0,
                            param_output_type = &quot;complete&quot;)



respuestas_2=consulta[[1]]
base_op=cbind(base_op,respuestas_2)</code></pre>
<p><br /></p>
<p>Los resultados tambi√©n me ayudan a reducir mi respuesta inicial para poder procesarlas creando, por ejemplo, conjuntos de c√≥digos m√°s amplios:</p>
<iframe src="t3.html" width="700" height="500">
</iframe>
<p><br />
<br /></p>
<hr />
<p>Esta es una idea inicial para uso de esta potente herramienta para nuestro trabajo orientado al procesamiento de grandes vol√∫menes de texto. Podr√≠an haber otros de asistencia a armado de c√≥digo para an√°lisis y visualizaci√≥n.
Espero que haya inspirado üôè!</p>
<hr />
<p><br />
<br /></p>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>Kleinberg, B. (2022). rgpt3: Making requests from R to the GPT-3 API (Version 0.3.1) [Computer software]. <a href="https://doi.org/10.5281/zenodo.7327667" class="uri">https://doi.org/10.5281/zenodo.7327667</a><a href="#fnref1" class="footnote-back">‚Ü©Ô∏é</a></p></li>
<li id="fn2"><p>Mellon, Jonathan and Bailey, Jack and Scott, Ralph and Breckwoldt, James and Miori, Marta, Does GPT-3 know what the Most Important Issue is? Using Large Language Models to Code Open-Text Social Survey Responses At Scale (December 22, 2022). Available at SSRN: <a href="https://ssrn.com/abstract=4310154" class="uri">https://ssrn.com/abstract=4310154</a> or <a href="http://dx.doi.org/10.2139/ssrn.4310154" class="uri">http://dx.doi.org/10.2139/ssrn.4310154</a><a href="#fnref2" class="footnote-back">‚Ü©Ô∏é</a></p></li>
</ol>
</div>
