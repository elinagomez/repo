---
aliases: [audio a texto]
title: 'Audio a Texto con whisper'
thumbnail: ""
authors: [elina]
date: '2023-08-16'
tags: [Ciencias sociales computacionales]
codefolding_show: hide
codefolding_nobutton: true
categories:
  - R
  - Python
summary: 2023-08-16 / Transcripción de audio a texto usando whisper
image:
  caption: ''
  focal_point: ''
  output:
  blogdown::html_page:
    toc: yes
    number_sections: true
    toc_depth: 4
featuredImage: ""
---




______________


Una de las tareas que debemos realizar quienes trabajamos con técnicas de investigación en ciencias sociales que se registran en formatos como videos o audios (ej. entrevistas, grupos de discusión), es su transcripción o pasaje a texto para hacerlos procesables ya sea cualitativa o cuantitativamente. Generalmente, es una tarea que hacemos de forma manual y nos permite un primer acercamiento analítico al material producido en la etapa de trabajo de campo. Sin embargo, en muchos casos la masividad o falta de tiempo hace que sea útil complementar la tarea con técnicas de transcripción automática con modelo entrenados para tal fin. 

______________


**1. Contexto**


Esta entrada tiene la intención de socializar una forma sencilla de realizar esa transcripción utilizando una librería de [Open AI](https://openai.com/) que se llama [whisper](https://openai.com/research/whisper) y permite obtener transcripciones en alta calidad aún en español. Para ello utilizamos en lenguaje de programación [Python](https://www.python.org/) combinado con un entorno para escribir y ejecutar código, que pertenece a Google denominado [Google Colab](https://colab.research.google.com) y que tiene la ventaja, en este caso, de poder conectar con archivos alojados en Drive. El uso del entorno tiene un cuota gratuita por cuenta de 12 horas de ejecución de GPU (como referencia, en mi caso 240 minutos de audio me llevaron 33 minutos de ejecución, usando el modelo _medio_ o _medium_). 

El mismo código sería posible ejecutarlo a nivel local directamente desde Python (o en R usando el paquete [audio.whisper](https://github.com/bnosac/audio.whisper)), sin embargo los requerimientos de memoria que tiene si contamos con muchos archivos podría hacer inviable su ejecución.  


**2. Pasos**

Como primer paso debemos tener una cuenta de Google para poder abrir el cuaderno en el cual estará y se ejecutará el código. 


  I. Abrimos [este archivo](https://colab.research.google.com/drive/1ZIZB87sYD92lh50sonxRo5dNos8d6d3d?usp=sharing) denominado _Audio_a_texto.ipynb_ que contiene todas las líneas necesarias para hacer la transcripción. 

  II. Hago una copia del archivo y le pongo el nombre que quiero con _Archivo_ -> _Guardar una copia en Drive_

  III. Voy al panel de Herramientas, abro _Entorno de ejecución_ -> _Cambiar tipo de entorno de ejecución_ -> _T4 GPU_


<iframe src="imagen1.png" width="700"  height="500"></iframe>


  IV. Creo las carpetas **Entrevistas** y **transcripciones** en el Drive propio.


  V. Voy ejecutando de a uno los 5 pasos que aparecen en el código, apretando la la flecha circular en cada uno de los pasos. Cuando aparece un tick en verde, significa que esa celda ya fue ejecutada correctamente. El paso 5 será el que más demore ya que es dónde se hacen efectivamente las transcripciones y su guardado. 
Acá un video en el cual ejecuto los primeros pasos:   



<iframe src="video.mp4" width="700"  height="500"></iframe>



**Nota:** si cerramos el archivo _Audio_a_texto.ipynb_, cuando lo volvemos a abrir, tenemos que ejecutar todo de nuevo desde el Paso 1. 

Voilá!













